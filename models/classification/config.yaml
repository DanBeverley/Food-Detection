data:
  metadata_path: "data/classification/metadata.json" 
  image_size: [224, 224] 
  batch_size: 16 
  split_ratio: 0.2

  # New: Depth Map Configuration
  use_depth_map: false
  depth_map_dir_name: "depth" # Name of the subfolder containing depth maps within an instance folder

  # New: Point Cloud Configuration
  use_point_cloud: false
  point_cloud_root_dir: "E:/_MetaFood3D_new_Point_cloud/Point_cloud" # Root directory for all point clouds
  point_cloud_sampling_rate_dir: "4096" # Subdirectory under point_cloud_root_dir indicating sampling rate
  point_cloud_suffix: "_sampled_1.ply" # Suffix for the point cloud file (e.g., <instance_id><suffix>)

  augmentation:
    enabled: true
    rotation_range: 20 
    width_shift_range: 0.1 
    height_shift_range: 0.1
    shear_range: 0.1
    zoom_range: 0.1
    horizontal_flip: true
    brightness_range: [0.8, 1.2] 

    # MixUp Augmentation (applied after batching)
    mixup:
      enabled: true
      alpha: 0.2 # Controls the intensity of interpolation, 0.2 is a common value

    # CutMix Augmentation (applied after batching, potentially after MixUp)
    cutmix:
      enabled: false # Set to true to enable CutMix
      alpha: 1.0 # Controls patch size distribution, 1.0 is common

  # New: Preprocessing for additional modalities
  modalities_preprocessing:
    depth:
      normalize: true
      # normalization_type: "min_max" # Options: "min_max" (scale to 0-1), "standard_score" (z-score)
      # For depth, typically raw values are in mm or meters. Scaling to 0-1 or using specific depth ranges might be needed.
      # We can also consider converting depth to disparity or other representations.
      # For now, let's assume depth images are single channel and will be normalized to [0, 1] if normalize=true.
      # Actual normalization strategy might need to be refined in data.py.

    point_cloud:
      num_points: 4096 # Target number of points (sample or pad to this number)
      normalize: true
      # normalization_type: "bounding_box_min_max" # Scale points within their bounding box to [-1, 1] or [0, 1]
      # Other options: "global_min_max" (if a global range is known), "mean_std_dev"
      # Actual normalization strategy to be implemented in data.py using trimesh/open3d.      

# Model Configuration 
model:
  architecture: "MobileNetV3Small" 
  use_pretrained_weights: true 
  fine_tune: true 
  fine_tune_layers: 15 

  # Classification Head Configuration
  classification_head:
    pooling: "GlobalAveragePooling2D" 
    dense_layers: [128] 
    dropout: 0.5 
    activation: "relu" 
    final_activation: "softmax"
    kernel_l2_factor: 0.001 

# --- Optimizer Configuration ---
optimizer:
  name: "Adam" 
  learning_rate: 0.0001 
  # momentum: 0.9 
  # weight_decay: 0.0001 

# Loss Function Configuration 
loss:
  name: "sparse_categorical_crossentropy" 

# Metrics Configuration
metrics: ["accuracy"] 

# Training Configuration
training:
  epochs: 100 
  use_mixed_precision: true
  use_tpu: false 
  callbacks:
    model_checkpoint:
      enabled: true
      monitor: "val_accuracy"
      mode: "max"
      save_best_only: true
      save_weights_only: false
      filename_template: "model_epoch-{epoch:02d}_val_acc-{val_accuracy:.2f}.h5"
    early_stopping:
      enabled: true
      monitor: "val_accuracy"
      mode: "max"
      patience: 20 
      restore_best_weights: true
    reduce_lr_on_plateau:
      enabled: true 
      monitor: "val_accuracy" 
      mode: "max" 
      factor: 0.2 
      patience: 7 
      min_lr: 0.000001
    tensorboard:
      enabled: true
      log_dir: "logs/classification/" 
      histogram_freq: 0 
      write_graph: false
      update_freq: "epoch"
    lr_scheduler:
      enabled: true
      name: "cosine_decay"
      alpha: 0.0

# Paths Configuration (Used by Train and Export)
paths:
  data_dir: "data/classification" 
  metadata_filename: "metadata.json" 
  label_map_dir: "data/classification" 
  label_map_filename: "label_map.json" 
  model_save_dir: "trained_models/classification/" 
  log_dir: "logs/classification/"
  tflite_export_dir: "trained_models/classification/exported/" 

export:
  tflite_filename: "classification_model_full_default.tflite" 

  # Quantization Settings
  quantization:
    type: "none" 
    representative_dataset: 
      enabled: true 
      num_samples: 100 