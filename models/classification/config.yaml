data:
  metadata_path: "data/classification/metadata.json" 
  image_size: [224, 224] 
  batch_size: 32  # Reduced for stable distributed training
  split_ratio: 0.2
  debug_max_total_samples: null # Disabled for production - use all samples

  # Data splits for better validation
  validation_split: 0.2
  test_split: 0.1
  random_seed: 42

  use_depth_map: true  # Enable for production testing
  depth_map_dir_name: "depth" 

  use_point_cloud: true  # Enable for production testing
  point_cloud_root_dir: "/kaggle/input/metafood3d-pointcloud/_MetaFood3D_new_Point_cloud/Point_cloud" 
  point_cloud_sampling_rate_dir: "4096" 
  point_cloud_suffix: "_sampled_1.ply" 

  # Production augmentation settings
  augmentation:
    enabled: true
    augment_training_data: true
    augment_validation_data: false
    
    # Production augmentation ranges
    rotation_range: 30
    width_shift_range: 0.15
    height_shift_range: 0.15
    shear_range: 0.15
    zoom_range: 0.2
    horizontal_flip: true
    brightness_range: [0.7, 1.3]
    
    # Additional augmentations for better generalization
    contrast_range: [0.8, 1.2]
    saturation_range: [0.8, 1.2]
    hue_range: 0.1
    
    # Noise and blur for robustness
    gaussian_noise_std: 0.02
    gaussian_blur_sigma: [0.1, 2.0]
    
    # Cutout/Random erasing - enabled for production
    random_erasing:
      enabled: true   # Enabled for production robustness
      probability: 0.25
      area_ratio_range: [0.02, 0.33]
      aspect_ratio_range: [0.3, 3.3]

  # Advanced augmentation techniques (applied after batching)
  advanced_augmentation:
    # MixUp Augmentation
    mixup:
      enabled: true
      alpha: 0.4

    # CutMix Augmentation
    cutmix:
      enabled: true
      alpha: 1.0
    
    # Label smoothing equivalent through augmentation
    label_smoothing_equivalent: 0.1

  modalities_preprocessing:
    depth:
      normalize: true

    point_cloud:
      num_points: 4096 
      normalize: true   

# Production Model Configuration
model:
  architecture: "MobileNetV3Small" 
  use_pretrained_weights: true 
  fine_tune: true 
  fine_tune_layers: -1  # Unfreeze ALL layers (-1 means all)

  # Production Classification Head with Regularization
  classification_head:
    pooling: "GlobalAveragePooling2D" 
    dense_layers: 
      - units: 512  # Increased for production
        dropout: 0.5 
        batch_norm: true
        l2_regularization: 0.0001
      - units: 256  # Increased for production
        dropout: 0.4
        batch_norm: true
        l2_regularization: 0.0001
    dropout_rate: 0.3
    activation: "relu" 
    final_activation: "softmax"
    
    # Regularization
    kernel_l2_factor: 0.002
    activity_l2_factor: 0.001

    # Batch normalization
    use_batch_norm: true
    batch_norm_momentum: 0.99

# Production Optimizer Configuration
optimizer:
  name: "AdamW"
  learning_rate: 0.002  # Scaled for distributed training
  weight_decay: 0.01
  clipnorm: 5.0  # Increased to allow larger gradients
  
  # Learning rate scheduling - enabled for production
  schedule:
    enabled: true
    type: "cosine_decay_restarts"
    initial_learning_rate: 0.002
    first_decay_steps: 2000
    t_mul: 2.0
    m_mul: 1.0
    alpha: 0.00001

# Production Loss Function Configuration 
loss:
  name: "CategoricalCrossentropy" 
  params:
    label_smoothing: 0.1
    from_logits: false

# Metrics Configuration
metrics: ["accuracy", "top_5_accuracy", "precision", "recall"] 

# Production Training Configuration
training:
  epochs: 30  # Increased for better convergence
  debug_epochs: 3   # Reduced debug epochs
  use_mixed_precision: false  # Disabled for debugging distributed training
  use_tpu: true  # Enabled for TPU v3-8 training 
  
  # Class weights for imbalanced datasets
  use_class_weights: true
  
  # Advanced augmentation parameters
  mixup_alpha: 0.4
  cutmix_alpha: 1.0
  
  # Production callbacks configuration
  callbacks:
    model_checkpoint:
      enabled: true
      monitor: "val_categorical_accuracy"
      mode: "max"
      save_best_only: true
      save_weights_only: false
      filename_template: "model_epoch-{epoch:02d}_val_acc-{val_categorical_accuracy:.4f}.h5"
      
    early_stopping:
      enabled: true
      monitor: "val_loss"
      mode: "min"
      patience: 12
      restore_best_weights: true
      min_delta: 0.001
      
    reduce_lr_on_plateau:
      enabled: true
      monitor: "val_loss" 
      mode: "min" 
      factor: 0.2
      patience: 5
      min_lr: 0.0000001
      cooldown: 3
      
    tensorboard:
      enabled: true
      log_dir: "logs/classification/" 
      histogram_freq: 1
      write_graph: true
      update_freq: "epoch"
      
    # Additional regularization callbacks
    lr_scheduler:
      enabled: true
      name: "cosine_decay_restarts"
      alpha: 0.0
      
    # Custom overfitting monitoring
    overfitting_monitor:
      enabled: true
      patience: 10
      min_delta: 0.02
      
    # Model complexity reduction
    model_pruning:
      enabled: false
      target_sparsity: 0.5
      
  # Training strategies
  strategies:
    # Gradual unfreezing
    gradual_unfreezing:
      enabled: true
      unfreeze_schedule: [5, 10, 15]
      
    # Progressive resizing
    progressive_resizing:
      enabled: false
      size_schedule: [[128, 128], [160, 160], [224, 224]]
      epoch_schedule: [0, 10, 20]

# Paths Configuration (Used by Train and Export)
paths:
  data_dir: "data/classification" 
  metadata_filename: "metadata.json" 
  label_map_dir: "data/classification" 
  label_map_filename: "label_map.json" 
  model_save_dir: "trained_models/classification/" 
  log_dir: "logs/classification/"
  tflite_export_dir: "trained_models/classification/exported/" 

export:
  keras_model_filename: "final_model.h5"
  tflite_filename: "classification_model_final.tflite"
  # Quantization Settings
  quantization:
    type: "int8" 
    representative_dataset: 
      enabled: true 
      num_samples: 100 