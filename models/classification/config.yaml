data:
  metadata_path: "C:/Users/ADMIN/Documents/GitHub/Food-Detection/data/dummy_classification/metadata.json" # Point to dummy metadata
  data_dir: "C:/Users/ADMIN/Documents/GitHub/Food-Detection/data/dummy_classification/processed"      # Point to dummy processed data
  image_size: [224, 224]
  batch_size: 32
  split_ratio: 0.2

  augmentation:
    enabled: true
    rotation_range: 20 # degrees
    width_shift_range: 0.1 # fraction of total width
    height_shift_range: 0.1 # fraction of total height
    shear_range: 0.1
    zoom_range: 0.1
    horizontal_flip: true
    brightness_range: [0.8, 1.2] # Min/max brightness factor

# Model Configuration 
model:
  architecture: "EfficientNetV2B0" # e.g., EfficientNetV2B0, EfficientNetV2S, ConvNeXtTiny
  use_pretrained_weights: true 
  fine_tune: false 
  fine_tune_layers: 10 

  # Classification Head Configuration
  classification_head:
    pooling: "GlobalAveragePooling2D" # 'GlobalAveragePooling2D' or 'GlobalMaxPooling2D' or 'Flatten'
    dense_layers: [256] 
    dropout: 0.5 
    activation: "relu" 
    final_activation: "softmax"

# --- Optimizer Configuration ---
optimizer:
  name: "Adam" # 'Adam', 'SGD', 'RMSprop' (potentially 'AdamW' if tensorflow-addons installed)
  learning_rate: 0.001
  # momentum: 0.9 # Only used for SGD
  # weight_decay: 0.0001 # Only used for AdamW

# Loss Function Configuration 
loss:
  name: "sparse_categorical_crossentropy" # 'sparse_categorical_crossentropy', 'categorical_crossentropy' (requires one-hot labels)

# --- Metrics Configuration ---
metrics: ["accuracy"] # List of metrics, e.g., ['accuracy', 'sparse_top_k_categorical_accuracy']

# Training Configuration
training:
  epochs: 1 # Set epochs to 1 for a quick test
  use_mixed_precision: false
  callbacks:
    model_checkpoint:
      enabled: true
      monitor: "val_loss"
      mode: "min"
      save_best_only: true
      save_weights_only: false
      filename_template: "model_epoch-{epoch:02d}_val_loss-{val_loss:.2f}.h5"
    early_stopping:
      enabled: true
      monitor: "val_loss"
      mode: "min"
      patience: 10
      restore_best_weights: true
    reduce_lr_on_plateau:
      enabled: true
      monitor: "val_loss"
      mode: "min"
      factor: 0.2
      patience: 5
      min_lr: 0.000001
    tensorboard:
      enabled: true
      log_dir: "logs/classification/" # Will be created relative to project root
      histogram_freq: 0 # Set to 1 to enable histograms (can consume disk space)
      write_graph: true
      update_freq: "epoch"
    lr_scheduler:
      name: "cosine_decay"
      alpha: 0.0

# Paths Configuration (Used by Train and Export)
paths:
  model_save_dir: "trained_models/classification/"
  log_dir: "logs/classification/"
  label_map_filename: "label_map.json" 
  tflite_export_dir: "trained_models/classification/exported/" 

export:
  tflite_filename: "classification_model.tflite"

  # Quantization Settings
  quantization:
    type: "default"
    representative_dataset: 
      enabled: true 
      num_samples: 100 

# Logging and checkpoints (Potentially redundant if paths are covered above)
checkpoint_dir: "trained_models/classification/checkpoints/"  # Directory for saving checkpoints
log_dir: "logs/classification/"  # Directory for TensorBoard logs or other logging